<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.551">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Phil">

<title>Warmup Exercises</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./assets/icons/favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title"><b>Machine Learning</b> | CSCI 0451 S24</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="./index.html"> 
<span class="menu-text">Syllabus</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./schedule.html"> 
<span class="menu-text">Schedule</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./assignments.html"> 
<span class="menu-text">Index of Assignments</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="./project.html"> 
<span class="menu-text">Course Project</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-score-based-classification" id="toc-sec-score-based-classification" class="nav-link active" data-scroll-target="#sec-score-based-classification">Graphing Decision Boundaries</a>
  <ul class="collapse">
  <li><a href="#part-a" id="toc-part-a" class="nav-link" data-scroll-target="#part-a">Part A</a></li>
  <li><a href="#part-b" id="toc-part-b" class="nav-link" data-scroll-target="#part-b">Part B</a></li>
  <li><a href="#part-c" id="toc-part-c" class="nav-link" data-scroll-target="#part-c">Part C</a></li>
  </ul></li>
  <li><a href="#sec-penguins" id="toc-sec-penguins" class="nav-link" data-scroll-target="#sec-penguins">Meet The Palmer Penguins!</a>
  <ul class="collapse">
  <li><a href="#part-a-1" id="toc-part-a-1" class="nav-link" data-scroll-target="#part-a-1">Part A</a></li>
  <li><a href="#part-b-1" id="toc-part-b-1" class="nav-link" data-scroll-target="#part-b-1">Part B</a></li>
  </ul></li>
  <li><a href="#sec-decision-theory" id="toc-sec-decision-theory" class="nav-link" data-scroll-target="#sec-decision-theory">Choosing a Threshold</a>
  <ul class="collapse">
  <li><a href="#part-a-2" id="toc-part-a-2" class="nav-link" data-scroll-target="#part-a-2">Part A</a></li>
  <li><a href="#part-b-2" id="toc-part-b-2" class="nav-link" data-scroll-target="#part-b-2">Part B</a></li>
  </ul></li>
  <li><a href="#sec-fairness" id="toc-sec-fairness" class="nav-link" data-scroll-target="#sec-fairness">Experiencing (Un)Fairness</a></li>
  <li><a href="#sec-bhn-comprehension" id="toc-sec-bhn-comprehension" class="nav-link" data-scroll-target="#sec-bhn-comprehension">Reading Check: BHN</a></li>
  <li><a href="#sec-perceptron" id="toc-sec-perceptron" class="nav-link" data-scroll-target="#sec-perceptron">Linear Models, Perceptron, and Torch</a>
  <ul class="collapse">
  <li><a href="#part-a-3" id="toc-part-a-3" class="nav-link" data-scroll-target="#part-a-3">Part A</a></li>
  <li><a href="#part-b-3" id="toc-part-b-3" class="nav-link" data-scroll-target="#part-b-3">Part B</a></li>
  <li><a href="#check" id="toc-check" class="nav-link" data-scroll-target="#check">Check</a></li>
  </ul></li>
  <li><a href="#sec-views-on-compas" id="toc-sec-views-on-compas" class="nav-link" data-scroll-target="#sec-views-on-compas">COMPAS and Equality of Opportunity</a></li>
  <li><a href="#sec-studying-up" id="toc-sec-studying-up" class="nav-link" data-scroll-target="#sec-studying-up">Power, Data, and Studying Up</a>
  <ul class="collapse">
  <li><a href="#scenarios" id="toc-scenarios" class="nav-link" data-scroll-target="#scenarios">Scenarios</a></li>
  </ul></li>
  <li><a href="#sec-data-sheets" id="toc-sec-data-sheets" class="nav-link" data-scroll-target="#sec-data-sheets">Data Context and Data Sheets</a>
  <ul class="collapse">
  <li><a href="#part-a-4" id="toc-part-a-4" class="nav-link" data-scroll-target="#part-a-4">Part A</a></li>
  <li><a href="#part-b-4" id="toc-part-b-4" class="nav-link" data-scroll-target="#part-b-4">Part B</a></li>
  </ul></li>
  <li><a href="#sec-convexity" id="toc-sec-convexity" class="nav-link" data-scroll-target="#sec-convexity">Practice with Convex Functions</a>
  <ul class="collapse">
  <li><a href="#part-a-5" id="toc-part-a-5" class="nav-link" data-scroll-target="#part-a-5">Part A</a></li>
  <li><a href="#part-b-5" id="toc-part-b-5" class="nav-link" data-scroll-target="#part-b-5">Part B</a></li>
  </ul></li>
  <li><a href="#sec-gradient-descent" id="toc-sec-gradient-descent" class="nav-link" data-scroll-target="#sec-gradient-descent">A First Look at Gradient Descent</a>
  <ul class="collapse">
  <li><a href="#part-a-6" id="toc-part-a-6" class="nav-link" data-scroll-target="#part-a-6">Part A</a></li>
  <li><a href="#part-b-6" id="toc-part-b-6" class="nav-link" data-scroll-target="#part-b-6">Part B</a></li>
  <li><a href="#part-c-1" id="toc-part-c-1" class="nav-link" data-scroll-target="#part-c-1">Part C</a></li>
  <li><a href="#part-d" id="toc-part-d" class="nav-link" data-scroll-target="#part-d">Part D</a></li>
  </ul></li>
  <li><a href="#sec-project-pitch" id="toc-sec-project-pitch" class="nav-link" data-scroll-target="#sec-project-pitch">Project Pitches</a></li>
  <li><a href="#sec-linear-systems-review" id="toc-sec-linear-systems-review" class="nav-link" data-scroll-target="#sec-linear-systems-review">Eigenvalues and Linear Systems</a>
  <ul class="collapse">
  <li><a href="#part-a-7" id="toc-part-a-7" class="nav-link" data-scroll-target="#part-a-7">Part A</a></li>
  <li><a href="#part-b-7" id="toc-part-b-7" class="nav-link" data-scroll-target="#part-b-7">Part B</a></li>
  </ul></li>
  <li><a href="#sec-kernels" id="toc-sec-kernels" class="nav-link" data-scroll-target="#sec-kernels">Introducing Kernels</a></li>
  <li><a href="#sec-gradient-descent-2" id="toc-sec-gradient-descent-2" class="nav-link" data-scroll-target="#sec-gradient-descent-2">Gradient Descent (Again)</a></li>
  <li><a href="#sec-overfitting" id="toc-sec-overfitting" class="nav-link" data-scroll-target="#sec-overfitting">Overfitting and the Scientific Method</a></li>
  <li><a href="#sec-erm" id="toc-sec-erm" class="nav-link" data-scroll-target="#sec-erm">The Coin-Flipping Game</a></li>
  <li><a href="#sec-classification-rates-2" id="toc-sec-classification-rates-2" class="nav-link" data-scroll-target="#sec-classification-rates-2">Balancing Classification Rates</a></li>
  <li><a href="#sec-limits-quantitative" id="toc-sec-limits-quantitative" class="nav-link" data-scroll-target="#sec-limits-quantitative">Limits of The Quantitative Approach to Discrimination</a></li>
  <li><a href="#sec-vectorization" id="toc-sec-vectorization" class="nav-link" data-scroll-target="#sec-vectorization">Vectorization Brainstorm</a></li>
  <li><a href="#sec-compression" id="toc-sec-compression" class="nav-link" data-scroll-target="#sec-compression">Image Compression Factor of K-Means</a>
  <ul class="collapse">
  <li><a href="#optional-extra" id="toc-optional-extra" class="nav-link" data-scroll-target="#optional-extra">Optional Extra</a></li>
  </ul></li>
  <li><a href="#sec-intro-tensors" id="toc-sec-intro-tensors" class="nav-link" data-scroll-target="#sec-intro-tensors">Introducing Tensors</a></li>
  <li><a href="#sec-backprop" id="toc-sec-backprop" class="nav-link" data-scroll-target="#sec-backprop">Efficient Differentiation</a>
  <ul class="collapse">
  <li><a href="#what-you-should-do" id="toc-what-you-should-do" class="nav-link" data-scroll-target="#what-you-should-do">What You Should Do</a></li>
  </ul></li>
  <li><a href="#sec-convolutional-kernel" id="toc-sec-convolutional-kernel" class="nav-link" data-scroll-target="#sec-convolutional-kernel">Convolutional Kernels</a></li>
  <li><a href="#sec-project-check-in" id="toc-sec-project-check-in" class="nav-link" data-scroll-target="#sec-project-check-in">Project Check-In</a></li>
  <li><a href="#sec-transfer-learning" id="toc-sec-transfer-learning" class="nav-link" data-scroll-target="#sec-transfer-learning">What Needs To Be Learned?</a></li>
  <li><a href="#sec-word-embedding" id="toc-sec-word-embedding" class="nav-link" data-scroll-target="#sec-word-embedding">Word Embedding</a></li>
  <li><a href="#sec-realistic-text" id="toc-sec-realistic-text" class="nav-link" data-scroll-target="#sec-realistic-text">Realistic Text?</a></li>
  <li><a href="#sec-mind-map" id="toc-sec-mind-map" class="nav-link" data-scroll-target="#sec-mind-map">Mind Map</a>
  <ul class="collapse">
  <li><a href="#flowcharts-in-quarto" id="toc-flowcharts-in-quarto" class="nav-link" data-scroll-target="#flowcharts-in-quarto">Flowcharts in Quarto</a></li>
  </ul></li>
  <li><a href="#sec-classification-rates" id="toc-sec-classification-rates" class="nav-link" data-scroll-target="#sec-classification-rates">Classification Rates</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header">
<h1 class="title display-7">Warmup Exercises</h1>
<p class="author">Phil</p>

</header>


<div class="hidden">
<p><span class="math display">\[
\newcommand{\R}{\mathbb{R}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\vw}{\mathbf{w}}
\newcommand{\vz}{\mathbf{z}}
\newcommand{\norm}[1]{\lVert #1 \rVert}
\newcommand{\bracket}[1]{\langle #1 \rangle}
\newcommand{\abs}[1]{\lvert #1 \rvert}
\newcommand{\paren}[1]{\left( #1 \right)}
\]</span></p>
</div>
<section id="sec-score-based-classification" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-score-based-classification">Graphing Decision Boundaries</h2>
<section id="part-a" class="level3">
<h3 class="anchored" data-anchor-id="part-a">Part A</h3>
<p>Sketch the line in <span class="math inline">\(\R^2\)</span> described by the equation <span id="eq-linear-boundary"><span class="math display">\[
\bracket{\vw, \vx}  =  b\;,
\tag{1}\]</span></span></p>
<p>where <span class="math inline">\(\vw = \paren{1, -\frac{1}{2}}^T \in \R^2\)</span> and <span class="math inline">\(b = \frac{1}{2}\)</span>. Here, <span class="math inline">\(\bracket{\vw, \vx} = \sum_{i = 1}^p w_i x_i\)</span> is the inner product (or dot product) between the vectors <span class="math inline">\(\vw,\vx \in \R^p\)</span>.</p>
</section>
<section id="part-b" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="part-b">Part B</h3>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="margin-aside">You can create <code>numpy</code> arrays like this: <code>x = np.array([0.2, 4.3])</code>. The syntax <code>x@w</code> can also be used as a convenient shorthand for <code>np.dot(x, w)</code>.</span></div></div>
<p>Write a quick Python function called <code>linear_classify(x, w, b)</code>. <code>w</code> and <code>x</code> should both be 1d <code>numpy</code> arrays of the same length, and <code>b</code> should be a scalar. The function <code>np.dot(x, w)</code> will compute the inner product of <code>x</code> and <code>w</code>. Argument <code>b</code> should be a scalar number. Your function should return <code>0</code> if if <span class="math inline">\(\bracket{\vw, \vx}  &lt;  b\)</span> and <code>1</code> if <span class="math inline">\(\bracket{\vw, \vx}  \geq  b\)</span>.</p>
<p>Verify that your function works on a few simple examples.</p>
</section>
<section id="part-c" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="part-c">Part C</h3>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="margin-aside">The function <span class="math inline">\(\phi\)</span> is an example of a <em>feature map</em>, which we will discuss soon.</span></div></div>
<p>Let <span class="math inline">\(\phi:\mathbb{R}^2\rightarrow \mathbb{R}^5\)</span> be the function</p>
<p><span class="math display">\[
\phi(\mathbf{x}) = \phi(x_1, x_2) = (x_1, x_2, x_1^2, x_2^2, x_1x_2)^T\;.
\]</span></p>
<p>Make a sketch of the curve in <span class="math inline">\(\R^2_+\)</span> (the nonnegative quadrant) defined by the equation</p>
<p><span class="math display">\[
\bracket{\vw, \phi(\vx)} = b\;,
\]</span></p>
<p>where <span class="math inline">\(\vw = (0, 0, 1, \frac{1}{4}, 0)^T\)</span> and <span class="math inline">\(b = 1\)</span>.</p>
</section>
</section>
<section id="sec-penguins" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-penguins">Meet The Palmer Penguins!</h2>
<div class="quarto-figure quarto-figure-center page-columns page-full">
<figure class="figure page-columns page-full">
<p><img src="https://allisonhorst.github.io/palmerpenguins/reference/figures/lter_penguins.png" class="img-fluid figure-img"></p>
<figcaption class="margin-caption">Image source: @allisonhorst. The Palmer Penguins data was originally collected by <span class="citation" data-cites="gormanEcologicalSexualDimorphism2014">Gorman, Williams, and Fraser (<a href="#ref-gormanEcologicalSexualDimorphism2014" role="doc-biblioref">2014</a>)</span> and was nicely packaged and released for use in the data science community by <span class="citation" data-cites="horstAllisonhorstPalmerpenguinsV02020">Horst, Hill, and Gorman (<a href="#ref-horstAllisonhorstPalmerpenguinsV02020" role="doc-biblioref">2020</a>)</span>.</figcaption>
</figure>
</div>
<p>Our data set for class today is the Palmer Penguins. This data set contains physiological measurements and species labels for several populations of Adelie, Chinstrap, and Gentoo penguins.</p>
<p>Open a fresh Jupyter notebook using the <code>ml-0451</code> Anaconda Python kernel. In a code cell, paste and run the following code in order to acquire the data set.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://raw.githubusercontent.com/PhilChodrow/ml-notes/main/data/palmer-penguins/palmer-penguins.csv"</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(url)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<section id="part-a-1" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="part-a-1">Part A</h3>
<p>Use a <code>pandas</code> summary table (<code>df.groupby(...).aggregate(...)</code>) to answer the following question: how does the mean mass of penguins vary by species and sex?</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://allisonhorst.github.io/palmerpenguins/reference/figures/culmen_depth.png" class="img-fluid figure-img"></p>
<figcaption>Image source: @allisonhorst.</figcaption>
</figure>
</div>
</div></div></section>
<section id="part-b-1" class="level3">
<h3 class="anchored" data-anchor-id="part-b-1">Part B</h3>
<p>Make a <a href="https://seaborn.pydata.org/generated/seaborn.scatterplot.html">scatterplot</a> of culmen length against culmen depth, with the color of each point corresponding to the penguin species.</p>
</section>
</section>
<section id="sec-decision-theory" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-decision-theory">Choosing a Threshold</h2>
<section id="part-a-2" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="part-a-2">Part A</h3>
<p>You wake up feeling a bit of a tickle in your throat. You take a COVID rapid test. Consider two scenarios:</p>
<ol type="a">
<li>The test comes up positive and you quarantine for five days. As it turns out, your throat tickle disappears after 1 day, and a lab test reveals that you did <strong>not</strong> actually have COVID.</li>
<li>The test comes up negative. You figure you must just have a common cold. You carry on your day as usual. After 5 days, you decide to get a lab test, which reveals that you have been COVID+ for the last 5 days.</li>
</ol>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="margin-aside">If it feels very difficult to come up with a single number to summarize the “cost” of each of these outcomes, that’s normal! In practice, designers of automated decision systems may need to assign comparable “costs” to injury, life, access to education, etc.</span></div></div>
<p>Using any assumptions that seem appropriate to you, assign a numerical <strong>cost</strong> to each of these scenarios. If it helps, you may assume that scenario (a) is 1 “unit of badness,” and that scenario (b) is <span class="math inline">\(k\)</span> times as bad as scenario (a). What’s your suggested value of <span class="math inline">\(k\)</span>?</p>
<p>Please write down your reasoning and your suggested value in a short paragraph.</p>
</section>
<section id="part-b-2" class="level3">
<h3 class="anchored" data-anchor-id="part-b-2">Part B</h3>
<p>Let’s now imagine that the rapid COVID test does not just give a yes/no answer, but actually a <em>score</em> describing the patient’s likelihood of COVID on a scale from 0 to 1. What score is high enough to merit you staying home, according to your costs from Part A? To answer this question, run the following code to create a simulated vector of <code>cases</code> (0 is COVID negative, 1 is COVID positive) and <code>scores</code> between 0 and 1.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>NUM_CASES  <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>PREVALENCE <span class="op">=</span> <span class="fl">0.1</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>NOISE      <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>cases  <span class="op">=</span> <span class="dv">1</span><span class="op">*</span>(np.random.rand(NUM_CASES) <span class="op">&lt;</span> PREVALENCE)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> np.exp(cases <span class="op">+</span> NOISE<span class="op">*</span>(np.random.rand(NUM_CASES))) <span class="op">/</span> np.exp(NOISE<span class="op">+</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Suppose that the recommendation on the rapid test is that a score above <span class="math inline">\(t\)</span> indicates a “positive” result and that you should quarantine.</p>
<ol type="1">
<li>Write a function which, given a candidate value of <span class="math inline">\(t\)</span>, computes the total “cost” of using that threshold. The cost is equal to the number of times scenario (a) occurs in this data set (from Part A), multiplied by the cost of scenario (a), plus the number of times scenario (b) occurs in this data set, multiplied by the cost of scenario (b).</li>
<li>Using a <code>for</code>-loop or any other technique, conduct a search to find the value of <span class="math inline">\(t\)</span> that minimizes the total cost.</li>
</ol>
</section>
</section>
<section id="sec-fairness" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-fairness">Experiencing (Un)Fairness</h2>
<p><em>In completing this warmup, please keep in mind that you will be asked to share with your group and potentially with the class.</em></p>
<p>Take 30 minutes to write two paragraphs.</p>
<p>In your first paragraph, please respond to the following prompt:</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>You can choose to discuss a decision that either unfairly harmed <strong>or</strong> unfairly benefited you.</p>
</div></div><blockquote class="blockquote">
<p>When was a time in your life in which you felt that <strong>you were the subject of an unfair decision</strong>? What was it about that decision that made it feel <strong>unfair</strong>, rather than just bad, disappointing, or surprising?</p>
</blockquote>
<p>In your second paragraph, please respond to the following prompt:</p>
<blockquote class="blockquote">
<p>Consider Figure 4 in the <a href="https://fairmlbook.org/introduction.html">Introduction</a> of <em>BHN</em>. In this figure, there are blue dots and green dots, where the colors correspond to hypothetical demographic attributes. We as the reader can choose what the colors mean.</p>
<ul>
<li>Suggest one possible meaning for the blue and green dots in which you would say that the classifier depicted in the figure is unproblematic from the perspective of fairness.</li>
<li>Suggest one possible meaning for the blue and green dots in which you would say that the classifier depicted in the figure is concerning from the perspective of fairness.</li>
<li>What is the relevant difference between the two cases?</li>
</ul>
</blockquote>
<p>Please bring your paragraphs to class and be ready to share with your group.</p>
</section>
<section id="sec-bhn-comprehension" class="level2">
<h2 class="anchored" data-anchor-id="sec-bhn-comprehension">Reading Check: BHN</h2>
<p>For each of the following soundbites, please write <strong>two sentences</strong> describing how <span class="citation" data-cites="barocasFairnessMachineLearning2023">Barocas, Hardt, and Narayanan (<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">2023</a>)</span> would respond. Please also include <strong>the number of the page</strong> on which you are basing your sentences in <a href="https://fairmlbook.org/pdf/fairmlbook.pdf">this PDF version of the book</a>. You might find useful discussion of the point on multiple pages; it’s sufficient to list one.</p>
<p>You may need to check both <a href="https://fairmlbook.org/classification.html">the reading for today</a> and the <a href="https://fairmlbook.org/introduction.html">reading from the previous lecture</a>.</p>
<ol type="1">
<li>“<em>Since the COMPAS algorithm didn’t use race as a predictor variable during training, it can’t be racially biased.</em>”</li>
<li>“<em>For every decision-making task, it is possible to ethically deploy an appropriately trained and audited automated decision model.</em>”</li>
<li>“<em>If two groups <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are on average equally deserving of access to an opportunity, then the only requirement of fairness is that a decision-making system accepts members of group <span class="math inline">\(a\)</span> at the same rate as members of group <span class="math inline">\(b\)</span>.</em>”</li>
<li>“<em>Decision-making algorithms should have equal error rates between different groups.</em>”</li>
<li>“<em>The data doesn’t lie, so the only fair approach to machine learning is to replicate patterns found in the data as accurately as possible.</em>”</li>
</ol>
</section>
<section id="sec-perceptron" class="level2">
<h2 class="anchored" data-anchor-id="sec-perceptron">Linear Models, Perceptron, and Torch</h2>
<p>In this warmup, you will introduce yourself to the model template code that we’ll use to implement several different machine learning models in this course. As you do so, you’ll use the Torch package (instead of Numpy) for numerical calculations.</p>
<p>Here’s a function which generates the kind of data we are going to use with the perceptron, including a feature matrix and a set of predictor labels. Instead of <code>np.array</code>s, these are now <code>torch.Tensor</code>s. You can still think of them as arrays of numbers with most of the same operations. Most things that you have learned about <code>np.array</code>s will still work for <code>torch.Tensor</code>s, and in this warmup I will point out all the relevant differences.</p>
<div id="cell-2" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">1234</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> perceptron_data(n_points <span class="op">=</span> <span class="dv">300</span>, noise <span class="op">=</span> <span class="fl">0.2</span>):</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> torch.arange(n_points) <span class="op">&gt;=</span> <span class="bu">int</span>(n_points<span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> y[:, <span class="va">None</span>] <span class="op">+</span> torch.normal(<span class="fl">0.0</span>, noise, size <span class="op">=</span> (n_points,<span class="dv">2</span>))</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> torch.cat((X, torch.ones((X.shape[<span class="dv">0</span>], <span class="dv">1</span>))), <span class="dv">1</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># convert y from {0, 1} to {-1, 1}</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> <span class="dv">2</span><span class="op">*</span>y <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X, y</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>X, y <span class="op">=</span> perceptron_data(n_points <span class="op">=</span> <span class="dv">300</span>, noise <span class="op">=</span> <span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here’s how it looks:</p>
<div id="cell-4" class="cell" data-execution_count="11">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="warmup-exercises_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>To define a classifier for this data, we are going to define three Python classes.</p>
<ul>
<li>The <code>LinearModel</code> class is a template for several linear models that we will implement in this class. Recall that a linear model is a model that works by computing a score for each data point like <span class="math inline">\(s_i = \langle \mathbf{w}, \mathbf{x}_i \rangle\)</span>. This class has a single instance variable: the weight vector <span class="math inline">\(\mathbf{w}\)</span>.</li>
<li>The <code>Perceptron</code> class inherits from <code>LinearModel</code> and describes the specific linear model we will use in lecture today.</li>
<li>The <code>PerceptronOptimizer</code> class will implement the specific learning algorithm that will improve the value of <span class="math inline">\(\mathbf{w}\)</span> in order to optimize an objective.</li>
</ul>
<p>Here are the three classes. I have written docstrings for the methods that we’ll implement in this warmup.</p>
<div id="cell-6" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> LinearModel:</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.w <span class="op">=</span> <span class="va">None</span> </span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> score(<span class="va">self</span>, X):</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="co">        Compute the scores for each data point in the feature matrix X. </span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">        The formula for the ith entry of s is s[i] = &lt;self.w, x[i]&gt;. </span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co">        If self.w currently has value None, then it is necessary to first initialize self.w to a random value. </span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co">        ARGUMENTS: </span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co">            X, torch.Tensor: the feature matrix. X.size() == (n, p), </span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co">            where n is the number of data points and p is the </span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co">            number of features. This implementation always assumes </span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="co">            that the final column of X is a constant column of 1s. </span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a><span class="co">        RETURNS: </span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a><span class="co">            s torch.Tensor: vector of scores. s.size() = (n,)</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.w <span class="kw">is</span> <span class="va">None</span>: </span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.w <span class="op">=</span> torch.rand((X.size()[<span class="dv">1</span>]))</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># your computation here: compute the vector of scores s</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span> </span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a><span class="co">        Compute the predictions for each data point in the feature matrix X. The prediction for the ith data point is either 0 or 1. </span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a><span class="co">        ARGUMENTS: </span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a><span class="co">            X, torch.Tensor: the feature matrix. X.size() == (n, p), </span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="co">            where n is the number of data points and p is the </span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a><span class="co">            number of features. This implementation always assumes </span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a><span class="co">            that the final column of X is a constant column of 1s. </span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a><span class="co">        RETURNS: </span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a><span class="co">            y_hat, torch.Tensor: vector predictions in {0.0, 1.0}. y_hat.size() = (n,)</span></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span> </span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Perceptron(LinearModel):</span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> loss(<span class="va">self</span>, X, y):</span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a><span class="co">        Compute the misclassification rate. A point i is classified correctly if it holds that s_i*y_i_ &gt; 0, where y_i_ is the *modified label* that has values in {-1, 1} (rather than {0, 1}). </span></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a><span class="co">        ARGUMENTS: </span></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a><span class="co">            X, torch.Tensor: the feature matrix. X.size() == (n, p), </span></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a><span class="co">            where n is the number of data points and p is the </span></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a><span class="co">            number of features. This implementation always assumes </span></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a><span class="co">            that the final column of X is a constant column of 1s. </span></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a><span class="co">            y, torch.Tensor: the target vector.  y.size() = (n,). The possible labels for y are {0, 1}</span></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a><span class="co">        HINT: In order to use the math formulas in the lecture, you are going to need to construct a modified set of targets and predictions that have entries in {-1, 1} -- otherwise none of the formulas will work right! An easy to to make this conversion is: </span></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a><span class="co">        </span></span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a><span class="co">        y_ = 2*y - 1</span></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>        <span class="co"># replace with your implementation</span></span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> grad(<span class="va">self</span>, X, y):</span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span> </span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> PerceptronOptimizer:</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model):</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model </span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> step(<span class="va">self</span>, X, y):</span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a>        <span class="co">"""</span></span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a><span class="co">        Compute one step of the perceptron update using the feature matrix X </span></span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a><span class="co">        and target vector y. </span></span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a><span class="co">        """</span></span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="part-a-3" class="level3">
<h3 class="anchored" data-anchor-id="part-a-3">Part A</h3>
<p>Open a fresh Jupyter notebook with the <code>ml-0451</code> kernel. Paste in the code that generates the data, as well as the three class definitions above.</p>
<p>Please implement <code>LinearModel.score()</code> and <code>LinearModel.predict()</code> according to their supplied docstrings.</p>
<p>An ideal solution will use <em>no</em> <code>for</code>-loops. It is possible to complete <code>LinearModel.score()</code> with one additional line of code and <code>LinearModel.predict()</code> with two lines of code.</p>
</section>
<section id="part-b-3" class="level3">
<h3 class="anchored" data-anchor-id="part-b-3">Part B</h3>
<p>Please implement <code>Perceptron.loss()</code> according to its supplied docstring. It is possible to complete this function with two lines of code.</p>
<p><em>Hints</em></p>
<ul>
<li>Two numbers <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> have the same sign iff <span class="math inline">\(ab &gt; 0\)</span>.</li>
<li>In <code>torch</code>, you can’t compute <code>a.mean()</code> if <code>a</code> is a boolean tensor. Instead, you need to cast <code>a</code> to a tensor of numerical values. One way to do this is by computing <code>(1.0*a).mean()</code>.</li>
</ul>
</section>
<section id="check" class="level3">
<h3 class="anchored" data-anchor-id="check">Check</h3>
<p>Once you have completed Parts A and B, the below code should run and the value of <code>l</code> should be <code>0.5</code>. Paste it into a new cell in your notebook and run it to check.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>p <span class="op">=</span> Perceptron()</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> p.score(X)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>l <span class="op">=</span> p.loss(X, y)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(l <span class="op">==</span> <span class="fl">0.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><em>There are several other methods in these classes that we will need to implement in order to have a functioning classification algorithm, but we won’t worry about those until later</em>.</p>
</section>
</section>
<section id="sec-views-on-compas" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-views-on-compas">COMPAS and Equality of Opportunity</h2>
<p><a href="https://www.philchodrow.prof/ml-notes/chapters/10-compas.html">Recently</a>, we replicated <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">ProPublica’s investigative reporting on the COMPAS algorithm</a> and <a href="https://www.philchodrow.prof/ml-notes/chapters/12-statistical-fairness.html">studied</a> several competing statistical definitions of fairness.</p>
<p>Imagine that this article came out two weeks ago. <strong>What should we do about the situation reported by ProPublica?</strong> Please address this question from three distinct perspectives:</p>
<ol type="1">
<li>The perspective of someone who adheres to the <em>narrow view</em> of equality of opportunity.</li>
<li>The perspective of someone who adheres to the <em>middle view</em> of equality of opportunity.</li>
<li>The perspective of someone who adheres to the <em>broad view</em> of equality of opportunity.</li>
</ol>
<div class="page-columns page-full"><p> Write at least three sentences from each of these perspectives. Your response should, at minimum, address the following two questions:</p><div class="no-row-height column-margin column-container"><span class="margin-aside">You may find it useful to remember from the readings that <em>calibration</em>, as discussed in BHN Ch. 4 is related to <em>sufficiency</em>, which is discussed in BHN Ch. 3 and also in <a href="https://www.philchodrow.prof/ml-notes/chapters/12-statistical-fairness.html">our notes on statistical conceptions of fairness</a>.</span></div></div>
<ul>
<li>Is the [narrow/middle/broad] view of equality of opportunity in fact violated, according to our previous data analysis?</li>
<li>If so, what change is obligated?</li>
<li>Whose obligation is it to enact that change? Whose obligation is it to incur the costs of that change?</li>
</ul>
<p>Please ground your sentences in our quantitative findings and our recent readings on <a href="https://fairmlbook.org/classification.html">statistical</a> and <a href="https://fairmlbook.org/relative.html">normative</a> notions of fairness. If you think the answer isn’t cut-and-dried, please do your best analysis and make a note about what’s complicated and why.</p>
</section>
<section id="sec-studying-up" class="level2">
<h2 class="anchored" data-anchor-id="sec-studying-up">Power, Data, and Studying Up</h2>
<p>For each of the hypothetical scenarios below, please:</p>
<ol type="a">
<li>Briefly analyze the scenario in terms of the four domains of the matrix of domination. Which of these domains are operating in the scenario provided? There are probably multiple, but not necessarily all four.</li>
<li>Suggest a way in which data scientists could “study up” <span class="citation" data-cites="barabasStudyingReorientingStudy2020">(<a href="#ref-barabasStudyingReorientingStudy2020" role="doc-biblioref">Barabas et al. 2020</a>)</span> by collecting and analyzing data about the powerful or privileged actors in the scenario.</li>
</ol>
<p>A concise paragraph for each scenario is plenty.</p>
<section id="scenarios" class="level3">
<h3 class="anchored" data-anchor-id="scenarios">Scenarios</h3>
<ol type="1">
<li>Landlords use an algorithm to predict “payment reliability” of prospective tenants in apartment complexes. The algorithm gives lower reliability scores to prospective tenants moving from predominantly Latinx/Hispanic neighborhoods than it does to prospective tenants moving from predominantly white neighborhoods.</li>
<li>Police use predictive policing algorithms that encourage them to allocate officers to neighborhoods that have historically had high arrest rates. A local politician tweets that these neighborhoods are “blighted.”</li>
<li>Medical professionals use a health score to determine which patients should receive palliative care. The score includes an assessment of pain levels as one of its inputs. <a href="https://www.aamc.org/news/how-we-fail-black-patients-pain">Doctors are known</a> to systematically underestimate the pain levels of Black patients in comparison to white ones.</li>
</ol>
</section>
</section>
<section id="sec-data-sheets" class="level2">
<h2 class="anchored" data-anchor-id="sec-data-sheets">Data Context and Data Sheets</h2>
<p><em>This warmup is based on Ch. 6 of <span class="citation" data-cites="dignazioDataFeminism2023">D’Ignazio and Klein (<a href="#ref-dignazioDataFeminism2023" role="doc-biblioref">2023</a>)</span> and <span class="citation" data-cites="gebruDatasheetsDatasets2021">Gebru et al. (<a href="#ref-gebruDatasheetsDatasets2021" role="doc-biblioref">2021</a>)</span></em>.</p>
<p>Let’s go back to our running example of the COMPAS data set. As you may remember, the data that feeds into a COMPAS risk score is collected by a screener using <a href="https://www.documentcloud.org/documents/2702103-Sample-Risk-Assessment-COMPAS-CORE">forms like this one</a>. Such risk assessments are administered to people who have been arrested and charged with criminal activity.</p>
<section id="part-a-4" class="level3">
<h3 class="anchored" data-anchor-id="part-a-4">Part A</h3>
<p>Using <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">the writeup from ProPublica</a> and any additional sources you are able to find, please respond to the following questions from <span class="citation" data-cites="gebruDatasheetsDatasets2021">Gebru et al. (<a href="#ref-gebruDatasheetsDatasets2021" role="doc-biblioref">2021</a>)</span> in order to construct a (very partial) datasheet for the COMPAS data set.</p>
<p>You may be able to answer many of these questions off the top of your head. For others, the answers might be a little blurry. For example, who created the COMPAS data set? Northpointe? The criminal penal system? ProPublica? In other cases, you might not know the answer – it’s fine to mark that and move on. Short responses are fine.</p>
<section id="motivation" class="level4">
<h4 class="anchored" data-anchor-id="motivation">Motivation</h4>
<ol type="1">
<li>For what purpose was the dataset created?</li>
<li>Who created the dataset (for example, which team, research group) and on behalf of which entity (for example, company, institution, organization)?</li>
</ol>
</section>
<section id="composition" class="level4">
<h4 class="anchored" data-anchor-id="composition">Composition</h4>
<ol type="1">
<li>What do the instances (rows) that comprise the dataset represent?</li>
<li>Does the dataset contain all possible instances or is it a sample (not necessarily random) of instances from a larger set?
<ul>
<li><em>Note</em>: this is another one that might take some thought.</li>
</ul></li>
<li>Does the dataset identify any subpopulations (for example, by age, gender)?</li>
<li>Is it possible to identify individuals (that is, one or more natural persons), either directly or indirectly (that is, in combination with other data) from the dataset?</li>
<li>Does the dataset contain data that might be considered sensitive in any way (for example, data that reveals race or ethnic origins, sexual orientations, religious beliefs, political opinions or union memberships, or locations; financial or health data; biometric or genetic data; forms of government identification, such as social security numbers; criminal history)?</li>
</ol>
</section>
<section id="collection-process" class="level4">
<h4 class="anchored" data-anchor-id="collection-process">Collection Process</h4>
<ol type="1">
<li>How was the data associated with each instance acquired?</li>
<li>Who was involved in the data collection process?</li>
<li>Did the individuals in question consent to the collection and use of their data?</li>
<li>If consent was obtained, were the consenting individuals provided with a mechanism to revoke their consent in the future or for certain uses?</li>
</ol>
</section>
<section id="uses" class="level4">
<h4 class="anchored" data-anchor-id="uses">Uses</h4>
<ol type="1">
<li>Has the data set been used for any tasks already?</li>
<li>What (other) tasks could the data set be used for?</li>
<li>Is there anything about the composition of the dataset or the way it was collected and preprocessed/ cleaned/labeled that might impact future uses? <em>For example, is there anything that a dataset consumer might need to know to avoid uses that could result in unfair treatment of individuals or groups (for example, stereotyping, quality of service issues) or other risks or harms (for example, legal risks, financial harms)? If so, please provide a description. Is there anything a dataset consumer could do to mitigate these risks or harms?</em></li>
<li>Are there tasks for which the dataset should not be used?</li>
</ol>
</section>
</section>
<section id="part-b-4" class="level3">
<h3 class="anchored" data-anchor-id="part-b-4">Part B</h3>
<p><span class="citation" data-cites="dignazioDataFeminism2023">D’Ignazio and Klein (<a href="#ref-dignazioDataFeminism2023" role="doc-biblioref">2023</a>)</span> emphasize the importance of the <em>context</em> of the data when deciding what data science to do and how to interpret it. Consider the following hypothetical, out-of-context statement:</p>
<blockquote class="blockquote">
<p>The COMPAS data set describes the the social background, thought patterns, criminal histories, and reoffenses for all criminal perpetrators in Broward County during the time period.</p>
</blockquote>
<p>In roughly one paragraph, analyze this statement against what you know about the <em>context</em> of the data, including your datasheet and our previous discussions. What context is missing from this statement? Which aspects of this statement are incorrect? Why does it matter?</p>
</section>
</section>
<section id="sec-convexity" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-convexity">Practice with Convex Functions</h2>
<section id="part-a-5" class="level3">
<h3 class="anchored" data-anchor-id="part-a-5">Part A</h3>
<p>Please write a careful mathematical proof of the following statement. You may cite without proving any of the statements <a href="https://sboyles.github.io/teaching/ce377k/convexity.pdf">from the reading</a> up to page 7. As suggested in the reading, Prop 2. (the second derivative test) is likely to be especially useful.</p>
<p><strong>Claim</strong>: Let <span class="math inline">\(f:\mathbb{R}\rightarrow\mathbb{R}\)</span> be any twice-differentiable and convex function. Then, the function <span class="math inline">\(g(x) = f(ax + b)\)</span> is also convex for any constants <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>.</p>
</section>
<section id="part-b-5" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="part-b-5">Part B</h3>
<p>The logistic sigmoid <span class="math inline">\(\sigma\)</span> is the function <span class="math inline">\(\sigma: \mathbb{R} \rightarrow \mathbb{R}\)</span> given by the formula <span class="math display">\[
\begin{aligned}
    \sigma(z) = \frac{1}{1 + e^{-z}}\;.
\end{aligned}
\]</span></p>
<section id="b.1" class="level4">
<h4 class="anchored" data-anchor-id="b.1">B.1</h4>
<p>Use <code>matplotlib</code> with either <code>numpy</code> or <code>torch</code> to make a graph of this function on the interval <span class="math inline">\(z \in [-1, 1]\)</span>.</p>
</section>
<section id="b.2" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="b.2">B.2</h4>
<div class="page-columns page-full"><p>Compute <span class="math inline">\(\frac{d\sigma(s_0)}{ds}\)</span>. </p><div class="no-row-height column-margin column-container"><span class="margin-aside"><span class="math inline">\(\frac{d\sigma(s_0)}{ds}\)</span> is the first derivative of <span class="math inline">\(\sigma\)</span> evaluated at the point <span class="math inline">\(s_0\)</span>. You may need to recall things like the chain and quotient rules.</span></div></div>
</section>
<section id="b.3" class="level4">
<h4 class="anchored" data-anchor-id="b.3">B.3</h4>
<p>Using your computation of <span class="math inline">\(\frac{d\sigma(s_0)}{ds}\)</span> from the previous part, check that the following formula holds. You should do so by computing both sides of the equation and verifying that they are equal.</p>
<p><span class="math display">\[
\begin{aligned}
    \frac{d\sigma(s_0)}{ds} = \sigma(s_0)\left(1 - \sigma(s_0)\right)\;.
\end{aligned}
\]</span></p>
</section>
<section id="b.4" class="level4">
<h4 class="anchored" data-anchor-id="b.4">B.4</h4>
<p>Using any methods from the reading, write a careful proof that the following two functions are convex:</p>
<ol type="1">
<li><span class="math inline">\(f(s) = - \log \sigma(s)\)</span></li>
<li><span class="math inline">\(g(s) = - \log (1 - \sigma(s))\)</span></li>
</ol>
</section>
<section id="b.5" class="level4">
<h4 class="anchored" data-anchor-id="b.5">B.5</h4>
<p>Let <span class="math inline">\(y \in \{0,1\}\)</span>. Explain why the function</p>
<p><span class="math display">\[
\ell(s, y) = - y \log \sigma(s) - (1  - y) \log(1-\sigma(s))
\]</span></p>
<p>is convex as a function of <span class="math inline">\(s\)</span>.</p>
</section>
</section>
</section>
<section id="sec-gradient-descent" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-gradient-descent">A First Look at Gradient Descent</h2>
<div class="page-columns page-full"><p>Let <span class="math inline">\(\mathbb{R}^+\)</span> be the set of strictly positive real numbers. Let <span class="math inline">\(a \in \mathbb{R}^+\)</span>. Consider the function <span class="math inline">\(g_a:\mathbb{R}^+ \rightarrow \mathbb{R}\)</span> with formula </p><div class="no-row-height column-margin column-container"><span class="margin-aside">Here and elsewhere in this class, <span class="math inline">\(\log\)</span> always refers to the <em>natural</em> log (base <span class="math inline">\(e\)</span>), which you may have also seen written <span class="math inline">\(\ln\)</span>.</span></div></div>
<p><span class="math display">\[
g_a(x) = \frac{1}{2}x^2 - a \log x\;.
\]</span></p>
<section id="part-a-6" class="level3">
<h3 class="anchored" data-anchor-id="part-a-6">Part A</h3>
<p>A <em>critical point</em> of <span class="math inline">\(g_a\)</span> is a point <span class="math inline">\(x_0\)</span> where <span class="math inline">\(\frac{dg_a(x_0)}{dx} = 0\)</span>. Find the critical point of this function in the set <span class="math inline">\(\mathbb{R}^+\)</span>. We’ll call this point <span class="math inline">\(x_a\)</span>.</p>
</section>
<section id="part-b-6" class="level3">
<h3 class="anchored" data-anchor-id="part-b-6">Part B</h3>
<p>Use the second derivative test to show that <span class="math inline">\(g_a\)</span> is strictly convex on the set <span class="math inline">\(\mathbb{R}^+\)</span>. It follows that the critical point <span class="math inline">\(x_a\)</span> is a global minimum of <span class="math inline">\(g_a\)</span>.</p>
</section>
<section id="part-c-1" class="level3">
<h3 class="anchored" data-anchor-id="part-c-1">Part C</h3>
<p>Implement the following algorithm as a Python function:</p>
<p><strong>Inputs</strong>: <span class="math inline">\(a \in \mathbb{R}^+\)</span>, tolerance <span class="math inline">\(\epsilon &gt; 0\)</span>, learning rate <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\mathrm{maxsteps} = 100\)</span>.</p>
<ol type="1">
<li>Start with an initial guess <span class="math inline">\(x = a\)</span>.</li>
<li>Set <span class="math inline">\(x' \gets 2a\)</span> and <span class="math inline">\(j \gets 0\)</span>.</li>
<li>While <span class="math inline">\(|x' - x| &gt; \epsilon\)</span>:
<ul>
<li>if <span class="math inline">\(j &gt; \mathrm{maxsteps}\)</span>
<ul>
<li>Break</li>
</ul></li>
<li><span class="math inline">\(x \gets x'\)</span></li>
<li><span class="math inline">\(x' \gets x - \alpha \frac{dg_a(x)}{dx}\)</span>;.</li>
<li><span class="math inline">\(j \gets j + 1\)</span>.</li>
</ul></li>
<li>Return <span class="math inline">\(x\)</span>.</li>
</ol>
<p>You should use the formula for <span class="math inline">\(\frac{dg_a(x)}{dx}\)</span> that you found in Part A.</p>
<p>Test your function like this:</p>
<pre class="{python}"><code>mystery_fun(a = 9, epsilon = 1e-8, alpha = 0.2)</code></pre>
<p>Please show:</p>
<ol type="1">
<li>One setting of <span class="math inline">\(\alpha\)</span> for which your function returns a real number very close to the exact value of <span class="math inline">\(x_a\)</span>.</li>
<li>One setting of <span class="math inline">\(\alpha\)</span> for which your function fails to return a real number close to the exact value of <span class="math inline">\(x_a\)</span> within the maximum number of steps.</li>
</ol>
</section>
<section id="part-d" class="level3">
<h3 class="anchored" data-anchor-id="part-d">Part D</h3>
<p>Is it possible to compute the positive square root of a positive real number using <em>only</em> the operations of addition, subtraction, multiplication, and division?</p>
</section>
</section>
<section id="sec-project-pitch" class="level2">
<h2 class="anchored" data-anchor-id="sec-project-pitch">Project Pitches</h2>
<p>Please pitch a project idea in the #project-pitches channel on Slack. Your project idea will not necessarily be the final project you work on — indeed, many of you will work on someone else’s idea. That’s ok! I am still expecting everyone to make a pitch.</p>
<p>First, read the course description of the project. Then, think about what you’d like to do!</p>
<p>Second, write your pitch! To write your pitch:</p>
<ol type="1">
<li>Write one or two sentences about <strong>the big picture</strong>: what problem you’d like to address and how machine learning fits in.</li>
<li>If your project needs data (almost all will), <strong>state your data plan</strong>. There are three ways:
<ol type="1">
<li>Describe a data set to which you currently have access.</li>
<li>Link to an online data set that is suitable for addressing your problem.</li>
<li>Describe a specific approach by which you will collect your own data.</li>
</ol></li>
<li>State <strong>what kind of problem</strong> your pitch involves. Is it a classification problem, a regression problem (predicting a quantitative outcome rather than a qualitative label), or an unsupervised problem like clustering?</li>
<li>Describe <strong>how you’ll judge whether your project is successful</strong>. What are you looking to have produced/achieved by the end of the semester?</li>
<li>Close your pitch by letting us know: <strong>why are you excited about this topic?</strong> Pitches are due as your warmup assignment on Tuesday 4/2.</li>
</ol>
</section>
<section id="sec-linear-systems-review" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-linear-systems-review">Eigenvalues and Linear Systems</h2>
<p>Consider the system of linear equations expressed in matrix-vector notation as</p>
<p><span id="eq-linear-system"><span class="math display">\[
\mathbf{A}\mathbf{x} = \mathbf{b}
\tag{2}\]</span></span></p>
<p>for some <em>square</em> matrix <span class="math inline">\(\mathbf{A} \in \mathbb{R}^{p \times p}\)</span> and vector <span class="math inline">\(\mathbf{b} \in \mathbb{R}^p\)</span>.</p>
<section id="part-a-7" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="part-a-7">Part A</h3>
<p>Suppose you are told that <a href="#eq-linear-system" class="quarto-xref">Equation&nbsp;2</a> has a <em>unique</em> solution in <span class="math inline">\(\mathbf{x}\)</span> for every possible choice of <span class="math inline">\(\mathbf{b}\in \mathbb{R}^p\)</span>.</p>
<div class="page-columns page-full"><p>Is <span class="math inline">\(\mathbf{A}\)</span> invertible? How do you know? <em>Find a statement of a theorem from linear algebra</em> that supports your claim. </p><div class="no-row-height column-margin column-container"><span class="margin-aside">It’s ok to look for the theorem online.</span></div></div>
</section>
<section id="part-b-7" class="level3">
<h3 class="anchored" data-anchor-id="part-b-7">Part B</h3>
<p>Let <span class="math inline">\(\alpha_1,\ldots, \alpha_p\)</span> be the eigenvalues of <span class="math inline">\(\mathbf{A}\)</span>. Suppose that <span class="math inline">\(\alpha_j \geq 0\)</span> for all <span class="math inline">\(j\)</span>, but that you don’t know anything else about <span class="math inline">\(\mathbf{A}\)</span>.</p>
<section id="b.1-1" class="level4">
<h4 class="anchored" data-anchor-id="b.1-1">B.1</h4>
<p>Can you be sure that <span class="math inline">\(\mathbf{A}\)</span> invertible? Explain how you know (find a theorem and cite it), or construct a counterexample.</p>
</section>
<section id="b.2-1" class="level4">
<h4 class="anchored" data-anchor-id="b.2-1">B.2</h4>
<p>Let <span class="math inline">\(\lambda &gt; 0\)</span>. Let <span class="math inline">\(\tilde{\mathbf{A}} = \mathbf{A} + \lambda \mathbf{I}\)</span>. What are the eigenvalues of <span class="math inline">\(\tilde{\mathbf{A}}\)</span>?</p>
</section>
<section id="b.3-1" class="level4">
<h4 class="anchored" data-anchor-id="b.3-1">B.3</h4>
<p>Is <span class="math inline">\(\tilde{\mathbf{A}}\)</span> invertible? Explain how you know (find a theorem and cite it), or give a counterexample.</p>
</section>
<section id="b.4-1" class="level4">
<h4 class="anchored" data-anchor-id="b.4-1">B.4</h4>
<p>Does the linear system <span class="math inline">\(\tilde{\mathbf{A}}\mathbf{x} = \mathbf{b}\)</span> have zero, one, or infinitely many solutions? Does the value of <span class="math inline">\(\mathbf{b}\)</span> matter? Explain how you know (find a theorem and cite it).</p>
</section>
</section>
</section>
<section id="sec-kernels" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-kernels">Introducing Kernels</h2>
<div class="page-columns page-full"><p>Suppose we have a set of 1-dimensional labeled data. </p><div class="no-row-height column-margin column-container"><span class="margin-aside">Unfold the code and copy it if you want to use it to generate your training data.</span></div></div>
<div id="cell-13" class="cell" data-execution_count="71">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>plt.style.use(<span class="st">'seaborn-v0_8-whitegrid'</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>n_points <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.rand(n_points)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> <span class="dv">1</span><span class="op">*</span>((x <span class="op">+</span> <span class="fl">0.3</span><span class="op">*</span>(torch.rand(n_points) <span class="op">-</span> <span class="fl">0.5</span>)) <span class="op">&gt;</span> <span class="fl">0.5</span> )</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_1d_classification_data(x, y, ax):</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>]</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    markers <span class="op">=</span> [<span class="st">"o"</span> , <span class="st">","</span>]</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">2</span>):</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        ix <span class="op">=</span> y <span class="op">==</span> targets[i]</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        ax.scatter(x[ix], torch.zeros_like(x[ix]), s <span class="op">=</span> <span class="dv">40</span>,  c <span class="op">=</span> y[ix], facecolors <span class="op">=</span> <span class="st">"none"</span>, edgecolors <span class="op">=</span> <span class="st">"darkgrey"</span>, cmap <span class="op">=</span> <span class="st">"BrBG"</span>, vmin <span class="op">=</span> <span class="op">-</span><span class="dv">1</span>, vmax <span class="op">=</span> <span class="dv">2</span>, alpha <span class="op">=</span> <span class="fl">0.6</span>, marker <span class="op">=</span> markers[i], )</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    ax.<span class="bu">set</span>(xlabel <span class="op">=</span> <span class="vs">r"$x$"</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize <span class="op">=</span> (<span class="dv">10</span>, <span class="dv">1</span>))</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>plot_1d_classification_data(x, y, ax)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="warmup-exercises_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>To learn in this data set, we are going to try a very different kind of classifier than we’ve used before. This is a <em>kernel classifier</em>.</p>
<p>For the purposes of this warmup, our kernel classifier computes a score for a data point with feature <span class="math inline">\(x\)</span> according to the formula</p>
<p><span id="eq-kernel"><span class="math display">\[
s = \sum_{i = 1}^n ye^{-\gamma (x - x_i )^2}\;,
\tag{3}\]</span></span></p>
<p>where <span class="math inline">\(\gamma\)</span> is some tunable positive constant. Roughly, the intuition of this score function is that you get a higher score by being “close” (having low distance) to lots of points where <span class="math inline">\(y = 1\)</span>.</p>
<p>Your warmup problem is to implement this score function. The code block below produces a range of possible values of <span class="math inline">\(x\)</span>:</p>
<div id="cell-15" class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>x_space <span class="op">=</span> torch.linspace(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1001</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Please write code to produce a vector <span class="math inline">\(\mathbf{s}\)</span> where the <span class="math inline">\(i\)</span>th element of <span class="math inline">\(s\)</span> is the score computed according to <a href="#eq-kernel" class="quarto-xref">Equation&nbsp;3</a>. It is possible to do this as a one-liner of under 80 characters if you are sneaky about it.</p>
<p><strong>Hint</strong>: you can compute a matrix of differences between every element of <code>x_space</code> and every element of the data <code>x</code> using the code below:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>diffs <span class="op">=</span> x_space[:, <span class="va">None</span>] <span class="op">-</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Once you have computed the vector <code>s</code>, try running the code below to visualize the fit of your score to the training data. For <span class="math inline">\(\gamma = 100\)</span>, I got something like this:</p>
<div id="cell-19" class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">1</span>, figsize <span class="op">=</span> (<span class="dv">5</span>, <span class="dv">4</span>), height_ratios<span class="op">=</span> (<span class="fl">0.8</span>, <span class="fl">0.2</span>))</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].plot(x_space, s, color <span class="op">=</span> <span class="st">"slategrey"</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>ax[<span class="dv">0</span>].<span class="bu">set</span>(ylabel <span class="op">=</span> <span class="st">"Kernel score"</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>plot_1d_classification_data(x, y, ax[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="warmup-exercises_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Produce versions of this plot for <span class="math inline">\(\gamma = 1\)</span>, <span class="math inline">\(\gamma = 100\)</span>, and <span class="math inline">\(\gamma = 10000\)</span>. What do you observe?</p>
</section>
<section id="sec-gradient-descent-2" class="level2">
<h2 class="anchored" data-anchor-id="sec-gradient-descent-2">Gradient Descent (Again)</h2>
<p>Consider the function <span class="math inline">\(f(w_0, w_1) = \sin(w_0w_1)\)</span>. You can define this function like this:</p>
<div id="cell-22" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> f(w):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.sin(w[<span class="dv">0</span>]<span class="op">*</span>w[<span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Mathematically, the gradient of this function is</p>
<p><span class="math display">\[\nabla f(w_0, w_1) = (w_1\cos w_0w_1, w_0 \cos w_0w_1)^T.\]</span></p>
<ol type="1">
<li>Implement a simple loop that uses gradient descent to find a minimum of this function.
<ul>
<li>You’ll have to choose the learning rate <span class="math inline">\(\alpha\)</span>.</li>
<li>The <code>np.cos()</code> function will be useful for programming the gradient.</li>
<li>It’s not the fastest approach, but if you’re not show how to program the gradient you can always first implement it as a list of two floats, and then use <code>np.array(my_list)</code> to convert it into a numpy array.</li>
<li>You’ll also need to pick a random starting guess.</li>
</ul></li>
<li>Find two initial guesses for the parameter vector <span class="math inline">\(\vw\)</span> such that you get two <em>different</em> final minimizers (this is possible because <span class="math inline">\(f\)</span> is not convex).</li>
</ol>
</section>
<section id="sec-overfitting" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-overfitting">Overfitting and the Scientific Method</h2>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="margin-aside"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/The_Scientific_Method.svg/520px-The_Scientific_Method.svg.png" class="img-fluid"> Image from <a href="https://en.wikipedia.org/wiki/Scientific_method">Wikipedia</a>.</span></div></div>
<p>In <a href="https://en.wikipedia.org/wiki/Scientific_method">the scientific method</a>, it is often emphasized that we need to formulate a hypothesis <em>before</em> performing an experiment. It’s fine for the hypothesis to be based on <em>previous</em> experiments. However, the scientific method never allows us to perform an experiment, formulate a hypothesis, and then say that the experiment supported the (new) hypothesis.</p>
<p>We can think of scientific theories as systems of thought that help us make predictions about new phenomena. With this in mind, <strong><em>please write a short paragraph explaining the importance of hypothesis-first science using the language of machine learning.</em></strong> In your explanation, please use the following vocabulary:</p>
<ul>
<li>Training data.</li>
<li>Training accuracy.</li>
<li>Validation/testing data.</li>
<li>Validation/testing accuracy.</li>
<li>Overfitting.</li>
</ul>
</section>
<section id="sec-erm" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-erm">The Coin-Flipping Game</h2>
<p>Let’s play a game! Here is the setup:</p>
<p>I have a coin with probability of heads equal to <span class="math inline">\(p \in [0,1]\)</span>. I am going to ask you to pick a number <span class="math inline">\(\hat{p} \in [0,1]\)</span>. Then, I flip my coin.</p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="margin-aside">This game is more fun for me than it is for you.</span></div></div>
<ul>
<li>If my coin comes up heads, you give me <span class="math inline">\(-\log \hat{p}\)</span> dollars.</li>
<li>If my coin comes up tails, you give me <span class="math inline">\(-\log (1-\hat{p})\)</span> dollars.</li>
</ul>
<section id="part-1" class="level4">
<h4 class="anchored" data-anchor-id="part-1">Part 1</h4>
<p>Compute the <em>expected</em> amount of money you will give me when we play this game in terms of <span class="math inline">\(p\)</span> and <span class="math inline">\(\hat{p}\)</span>. Call this quantity <span class="math inline">\(R(\hat{p}, p)\)</span>. This is the <em>risk</em> of the guess <span class="math inline">\(\hat{p}\)</span>.</p>
</section>
<section id="part-2" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="part-2">Part 2</h4>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="margin-aside">Take the derivative and set it equal to 0! Don’t forget to check that you’ve found a minimum of <span class="math inline">\(R(\hat{p}, p)\)</span> rather than a maximum or an inflection point.</span></div></div>
<p>Suppose I tell you the value of <span class="math inline">\(p\)</span>. Write a mathematical proof to show that your best choice of <span class="math inline">\(\hat{p}\)</span> (the one that loses you the least money) is <span class="math inline">\(\hat{p} = p\)</span>.</p>
</section>
<section id="part-3" class="level4">
<h4 class="anchored" data-anchor-id="part-3">Part 3</h4>
<p>Now suppose that I <em>don’t</em> tell you the true value of <span class="math inline">\(p\)</span>. Instead, I let you observe <span class="math inline">\(n\)</span> coin flips before asking you to make your guess. Describe:</p>
<ul>
<li>A suggestion for choosing <span class="math inline">\(\hat{p}\)</span> based only on the results of the previous flips.</li>
<li>A way to estimate the risk (expected amount of money lost) based only on the results of the previous flips.</li>
</ul>
<p>Your answer should depend on <span class="math inline">\(\hat{p}\)</span> but not on <span class="math inline">\(p\)</span>!</p>
</section>
</section>
<section id="sec-classification-rates-2" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-classification-rates-2">Balancing Classification Rates</h2>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="margin-aside">You can do this first part just by copying and pasting lecture code. It doesn’t matter much how good your model is – just make sure you’re able to get predictions.</span></div></div>
<p>Use the code from <a href="./lecture-notes/classification-in-practice.qmd">our recent lecture</a> to download the Titanic data set as a Pandas data frame and train a model on the training data. Then download the test data. Compute <code>y_pred</code>, the vector of predictions of your model on the test data.</p>
<p>Then, write a function that verifies eq. (2.6) in Alexandra Chouldechova’s paper “<a href="https://via.hypothes.is/https://arxiv.org/pdf/1703.00056.pdf">Fair Prediction with disparate impact</a>.” Here’s what your function should do:</p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="margin-aside">The positive predictive value is <span class="math inline">\(\mathrm{PPV} = \frac{\mathrm{TP}}{\mathrm{TP} + \mathrm{FP}}\)</span>.</span></div></div>
<ol type="1">
<li>Given vectors <code>y_pred</code> of predictions and <code>y_test</code> of actual labels, compute the False Negative Rate (FNR), False Positive Rate (FPR), prevalence <span class="math inline">\(p\)</span>, and positive predictive value (PPV).</li>
<li>Return as a tuple the lefthand side and righthand side of eq. (2.6) in Chouldechova.</li>
<li>Verify that the two numbers are equal!</li>
</ol>
</section>
<section id="sec-limits-quantitative" class="level2">
<h2 class="anchored" data-anchor-id="sec-limits-quantitative">Limits of The Quantitative Approach to Discrimination</h2>
<p>I’ll give you each a number in Slack. The numbers correspond to the following sections of <span class="citation" data-cites="narayanan2022limits">Narayanan (<a href="#ref-narayanan2022limits" role="doc-biblioref">2022</a>)</span>. These are:</p>
<ol type="1">
<li>The null hypothesis allocates the burden of proof (p.&nbsp;7-8)</li>
<li>Compounding inequality is far below the radar of quantitative methods (p.&nbsp;9-10)</li>
<li>Snapshot datasets hide discrimination (p.&nbsp;10-11)</li>
<li>Explaining away discrimination (p.&nbsp;12-13)</li>
<li>What counts as evidence is a subjective choice (p.&nbsp;5-7)</li>
</ol>
<p>For your assigned section, please write a short paragraph (4-5 simple sentences is fine). You should:</p>
<ul>
<li>Summarize Narayanan’s key points in that section.</li>
<li>In one of the sentences, describe which aspects of the Uber case study (p.&nbsp;13-16) reflect the ideas of the section you described.</li>
</ul>
<p>Bring your paragraph in class and be ready to read it to your group.</p>
</section>
<section id="sec-vectorization" class="level2">
<h2 class="anchored" data-anchor-id="sec-vectorization">Vectorization Brainstorm</h2>
<p>In a <a href="lecture-notes/vectorization.qmd">recent lecture</a>, we discussed methods of vectorizing text like the document-term matrix that use the <em>bag of words</em> assumption: the order of the words doesn’t matter!</p>
<p>Take some time and propose an alternative approach to word-based text vectorization. Can you find a scheme that would give different vector representations to the following two sentences?</p>
<blockquote class="blockquote">
<p>“I love rabbits, not cats.” “I love cats, not rabbits.”</p>
</blockquote>
<p>You don’t have to implement your vectorization, but please be prepared to write pseudocode for your group to show in detail how you would perform the vectorization.</p>
</section>
<section id="sec-compression" class="level2">
<h2 class="anchored" data-anchor-id="sec-compression">Image Compression Factor of K-Means</h2>
<p>In <a href="https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html">today’s reading</a> on K-means clustering from the Python Data Science Handbook, Jake VanderPlas considers the use of K-means to reduce the number of distinct colors in an image (Example 2). I encourage you to run the code for this example while thinking about this warmup!</p>
<p>Give an estimate of the <em>compression factor</em>: the reduction of information achieved when compressing an image using k-means clustering into <span class="math inline">\(k\)</span> color clusters. The compression factor is the number of bits required to store the compressed image, divided by the number of bits required to store the original image. Both of these numbers can be computed asymptotically (i.e.&nbsp;with big-oh reasoning) in order to simplify the analysis.</p>
<p>There are multiple good ways to think about this question, and you’re welcome to choose one that makes sense to you <em>as long as you carefully state your steps and assumptions</em>. Here are a few points that I find helpful:</p>
<section id="bits-in-original-image" class="level4">
<h4 class="anchored" data-anchor-id="bits-in-original-image">Bits in Original Image</h4>
<ol type="1">
<li>An image with <span class="math inline">\(n\)</span> rows and <span class="math inline">\(m\)</span> columns has <span class="math inline">\(nm\)</span> pixels.</li>
<li>Each pixel has one of three RGB color channels (Red, Green, and Blue).</li>
<li>Each color channel can be represented with 8 bits (which encode an integer between 0 and 255, denoting the color intensity in that channel).</li>
</ol>
</section>
<section id="bits-in-compressed-image" class="level4">
<h4 class="anchored" data-anchor-id="bits-in-compressed-image">Bits in Compressed Image</h4>
<ol type="1">
<li>If I compress an image into just <span class="math inline">\(k\)</span> distinct colors, then instead of storing the full RGB value for each pixel, I can just store enough bits to uniquely identify the cluster containing each pixel. How many bits do I need for this?</li>
<li>I also need to store a dictionary (hash map) that associates color <span class="math inline">\(j\)</span> (i.e.&nbsp;the centroid of the <span class="math inline">\(j\)</span>th cluster of colors) to its RGB value.</li>
</ol>
</section>
<section id="optional-extra" class="level3">
<h3 class="anchored" data-anchor-id="optional-extra">Optional Extra</h3>
<p>Try running the code above while varying the number of clusters. Do you think that a 16-color compression looks much better than an 8-color compression. Do you think the difference is good enough to justify approximately twice the storage? What about 32 colors vs.&nbsp;16?</p>
</section>
</section>
<section id="sec-intro-tensors" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-intro-tensors">Introducing Tensors</h2>
<p><strong>First</strong>, install <a href="https://pytorch.org/">PyTorch</a> 2.0 into your <code>ml-0451</code> Anaconda environment.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>The best way to install PyTorch is is probably to run the following at the command line:</p>
<pre><code>conda activate ml-0451
pip3 install torch torchvision torchaudio</code></pre>
</div></div><p><strong>Then</strong>, in a blank Jupyter notebook, copy, paste, and run each of the code blocks in the <a href="https://pytorch.org/tutorials/beginner/basics/tensor_tutorial.html">first section</a> of the PyTorch tutorial.</p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="margin-aside">You may need to do a little bit of exploring around the tutorials in order to come up with answers to these questions.</span></div></div>
<p><strong>Finally</strong>, write down a single-sentence answer to each of the following questions:</p>
<ol type="1">
<li>In what ways is a PyTorch tensor <em>similar</em> to a Numpy array?</li>
<li>In what ways is a PyTorch tensor <em>different</em> from a Numpy array?</li>
<li>What is the primary motivation for the use of a specialized tensor data type, rather than an array, for deep learning?</li>
</ol>
</section>
<section id="sec-backprop" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-backprop">Efficient Differentiation</h2>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="margin-aside">This exercise is based on <a href="https://chinmayhegde.github.io/dl-notes/notes/lecture02/#sgd-and-neural-networks">a section of Chinmay Hegde’s notes</a> on stochastic gradient descent and neural networks:</span></div></div>
<p>Consider the following function: <span class="math display">\[
L(w, b) = \frac{1}{2} \left(y - \sigma(wx + b)\right)^2 + \frac{1}{2}\lambda w^2\;,
\]</span></p>
<p>where <span class="math inline">\(\sigma(a) = \frac{1}{1 + e^{-a}}\)</span>.</p>
<p>This is the loss function that would be obtained when using a single feature <span class="math inline">\(x\)</span> to predict <span class="math inline">\(y\)</span>, using the function <span class="math inline">\(\sigma(wx + b)\)</span> the predictor and measuring the quality of this predictor using the square-error loss function. Our aim is to compute the gradient of <span class="math inline">\(L\)</span> with respect to <span class="math inline">\(w\)</span> and <span class="math inline">\(b\)</span>, with a “ridge” regularization term <span class="math inline">\(\frac{1}{2}\lambda w^2\)</span> that encourages the weight <span class="math inline">\(w\)</span> to be small.</p>
<div class="page-columns page-full"><p></p><div class="no-row-height column-margin column-container"><span class="margin-aside">I’ve used the property of the sigmoid that <span class="math inline">\(\sigma'(a) = \sigma(a)(1-\sigma(a))\)</span>.</span></div></div>
<p>The gradient of <span class="math inline">\(L\)</span> is <span class="math inline">\(\nabla L (w, b) = \left(\frac{\partial L}{\partial w}, \frac{\partial L}{\partial b}\right)\)</span>, where</p>
<p><span id="eq-explicit-gradient"><span class="math display">\[
\begin{aligned}
\frac{\partial L}{\partial w} &amp;= (\sigma(wx + b) - y)\sigma(wx+b)(1 - \sigma(wx+b))x + \lambda w \\
\frac{\partial L}{\partial b} &amp;= (\sigma(wx + b) - y)\sigma(wx+b)(1 - \sigma(wx+b))\;.
\end{aligned}
\tag{4}\]</span></span></p>
<section id="what-you-should-do" class="level3">
<h3 class="anchored" data-anchor-id="what-you-should-do">What You Should Do</h3>
<p>Assume that each of the following operations cost one computational unit:</p>
<ul>
<li>Multiplying or dividing two scalar numbers.</li>
<li>Adding or subtracting two scalar numbers.</li>
<li>Computing an exponential like <span class="math inline">\(e^a\)</span>.</li>
</ul>
<p>Using this assumption:</p>
<ol type="1">
<li>Determine the number of computational units (i.e.&nbsp;computational cost) of computing the gradient of <span class="math inline">\(L\)</span> exactly as written in <a href="#eq-explicit-gradient" class="quarto-xref">Equation&nbsp;4</a>, under the assumption that you are not allowed to store the values of any intermediate computations.</li>
<li>Now determine the computational cost of computing the gradient of <span class="math inline">\(L\)</span> under the assumption that you are allowed to store intermediate computations. Please describe both the number of computations and the number of floating point numbers that must be stored.</li>
<li>Finally, determine the computational cost in terms of both steps and storage to compute <span class="math inline">\(L\)</span> using the backpropagation algorithm (described for a very similar function in <a href="https://chinmayhegde.github.io/dl-notes/notes/lecture02/#sgd-and-neural-networks">Hegde’s notes</a>).</li>
</ol>
<p>Compare your results from each method.</p>
</section>
</section>
<section id="sec-convolutional-kernel" class="level2">
<h2 class="anchored" data-anchor-id="sec-convolutional-kernel">Convolutional Kernels</h2>
<p>Implement kernel convolution for extracting features from images. Your implementation should accept a 2d array <code>X</code> (think of <code>X</code> as representing a greyscale image) and a square convolutional kernel <code>K</code>. Your implementation should operate using pure <code>torch</code>. You can use any zero-padding strategy, but you do need to explain what your strategy is when presenting.</p>
<p>It’s ok to use a for-loop to loop over pixels.</p>
<p>Here’s an example image you can use:</p>
<div id="cell-24" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> urllib.request</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> read_image(url):</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    urllib.request.urlretrieve(url, <span class="st">"maru.png"</span>)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    img <span class="op">=</span> Image.<span class="bu">open</span>(<span class="st">"maru.png"</span>)</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.tensor(np.array(img)<span class="op">/</span><span class="dv">255</span>).<span class="bu">float</span>()</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://github.com/middlebury-csci-0451/CSCI-0451-s24/blob/main/assets/img/figs/maru.png?raw=true"</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> read_image(url)</span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> to_greyscale(im):</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    v <span class="op">=</span> torch.tensor([<span class="fl">0.2989</span>, <span class="fl">0.5870</span>, <span class="fl">0.1140</span>])</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">1</span> <span class="op">-</span> img[:,:,:<span class="dv">3</span>]<span class="op">@</span>v</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>img <span class="op">=</span> to_greyscale(img)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>plt.imshow(img, cmap <span class="op">=</span> <span class="st">"Greys"</span>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>no_ax <span class="op">=</span> plt.gca().axis(<span class="st">"off"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="warmup-exercises_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>After implementing your function, you should be able to use it like this, replacing the implementation of <code>scipy.signal</code> with your own implementation. The result should look something like this:</p>
<div id="cell-26" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.signal <span class="im">import</span> convolve2d</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>kernel <span class="op">=</span> torch.tensor([[<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>], </span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>                       [<span class="op">-</span><span class="dv">1</span>,  <span class="dv">8</span>, <span class="op">-</span><span class="dv">1</span>], </span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>                       [<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]])</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>convd <span class="op">=</span> convolve2d(img, kernel)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>plt.imshow(convd, cmap <span class="op">=</span> <span class="st">"Greys"</span>, vmin <span class="op">=</span> <span class="dv">0</span>, vmax <span class="op">=</span> <span class="fl">0.1</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>plt.gca().axis(<span class="st">"off"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="warmup-exercises_files/figure-html/cell-11-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>It is possible to implement kernel convolution as a function in 5-10 carefully-chosen lines of code.</p>
</section>
<section id="sec-project-check-in" class="level2">
<h2 class="anchored" data-anchor-id="sec-project-check-in">Project Check-In</h2>
<p><em>This is a warmup activity that we will repeat weekly until the end of the semester.</em></p>
<p>Prepare a 2-3 minute “presentation” of your project to your group. Your presentation can be informal and does not need to have any special visual aids. The primary expectation is that you are able to demonstrate <em>some relevant functionality</em> to your peers. If your project involves coding or data analysis, your relevant functionality might be as simple as accessing or preparing the data. You should plan to demonstrate additional functionality each week.</p>
<p>In other words, you should show your group <em>something that works</em>, regardless of how “big” it is.</p>
<p>If you are doing a project that does not involve implementation (such as a research essay), then you are still expected to offer an update. Your contributions could include describing the sources you’ve found or showing your group an outline of the argument that you will make.</p>
<p>It’s appropriate for each member of your project group to give the same presentation during warmup. <strong>Please note that you may not be in the same warmup group as your project partners</strong>. This means that:</p>
<ul>
<li>The code you show needs to run on <em>your</em> laptop or in <em>your</em> compute instance (e.g.&nbsp;Google Colab).</li>
<li><em>You</em> need to be ready to explain what is being shown, even if your project partners did much of the work.</li>
</ul>
</section>
<section id="sec-transfer-learning" class="level2">
<h2 class="anchored" data-anchor-id="sec-transfer-learning">What Needs To Be Learned?</h2>
<p>Suppose that you wanted to teach an individual to recognize English-language <a href="https://consumer.ftc.gov/articles/how-recognize-and-avoid-phishing-scams">phishing emails</a>. Write down a few features (based on the linked website, your own experience, or other sources) that you think would help someone classify an email as “phishing attempt or not” based on the text of the email.</p>
<p>Now, imagine that you are going to sit down with your tutee to teach them how to recognize English-language phishing emails. Where would you start your instruction if…</p>
<ol type="1">
<li>Your tutee was another member of your warmup group.</li>
<li>Your tutee was a fluent English speaker but had never used email.</li>
<li>Your tutee was a regular email user but spoke no English.</li>
<li>Your tutee spoke no English and had never seen a computer.</li>
</ol>
<p>Which of these four scenarios would require the most “learning effort?” Which would require the least?</p>
</section>
<section id="sec-word-embedding" class="level2">
<h2 class="anchored" data-anchor-id="sec-word-embedding">Word Embedding</h2>
<p>Take out a sheet of paper and a pencil. Your goal is to place the following words on the sheet of paper in such a way that their location on the sheet is indicative of their relationships to each other. You can decide exactly how to do this. Should words with similar meanings be in the same part of the page? Should pairs of words with similar <em>relationships</em> have similar distances? Your approach is up to you, but please <strong>write it down</strong> along with your placements. Your words are:</p>
<ul>
<li><em>Woman</em></li>
<li><em>Student</em></li>
<li><em>Nurse</em></li>
<li><em>Doctor</em></li>
<li><em>Man</em></li>
<li><em>Professor</em></li>
<li><em>Model</em></li>
<li><em>Computer</em></li>
<li><em>Machine</em></li>
<li><em>Programmer</em></li>
</ul>
</section>
<section id="sec-realistic-text" class="level2">
<h2 class="anchored" data-anchor-id="sec-realistic-text">Realistic Text?</h2>
<p>In our reading on <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/">The Unreasonable Effectiveness of Recurrent Neural Networks</a>, there are a few examples of model output that is <em>realistic</em> but not <em>real</em>. Pick one of the examples, and write down as carefully as you are able what makes the generated text <em>realistic</em>. Then, describe what “tells” would tip off an attentive observer that the text isn’t real (generated intentionally by a human) after all.</p>
<p>The Shakespeare and Wikipedia examples might be the easiest ones to think about, but feel free to look at the <span class="math inline">\(\LaTeX\)</span> or Linux source code examples if you prefer.</p>
</section>
<section id="sec-mind-map" class="level2">
<h2 class="anchored" data-anchor-id="sec-mind-map">Mind Map</h2>
<p>Wow, we’ve covered a lot of ground in this class! Use a graphics program or a pen/paper to make a mind map describing some of our main theoretical and concepts. As a reminder, a mind-map is a graph in which the nodes are concepts and edges join related concepts. Please incorporate the following concepts as nodes:</p>
<ul>
<li><em>Loss function</em></li>
<li><em>Target</em></li>
<li><em>Predictor</em></li>
<li><em>Model</em></li>
<li><em>Regression</em></li>
<li><em>Classification</em></li>
<li><em>Empirical risk minimization</em></li>
<li><em>Gradient descent</em></li>
<li><em>Feature map</em></li>
<li><em>Vectorization</em></li>
<li><em>Overfitting</em></li>
<li><em>Training data</em></li>
<li><em>Validation/testing data</em></li>
<li><em>Perceptron</em></li>
<li><em>Logistic regression</em></li>
<li><em>Neural networks</em></li>
<li><em>Linear regression</em></li>
</ul>
<p>Additionally, please incorporate <strong>at least three other concepts of your own choosing</strong>.</p>
<section id="flowcharts-in-quarto" class="level3">
<h3 class="anchored" data-anchor-id="flowcharts-in-quarto">Flowcharts in Quarto</h3>
<p>Since mind-maps can be a little complicated to organize, you might find it easiest to work with some software. One <strong>optional</strong> possibility is actually included with Quarto: the <a href="https://mermaid.js.org/">Mermaid</a> chart tool can render attractive diagrams that include labeled nodes and directed edges. Using a <a href="https://mermaid.js.org/syntax/flowchart.html">flowchart</a> is probably the way. For example, inserting the following code into a special <code>{mermaid}</code> code block will produce the following diagram:</p>
<pre><code>flowchart TB
    A(First concept) --&gt; B(Second concept)
    B --is part&lt;br&gt; of--&gt; A
    B--&gt;C(Third concept)
    A--&gt;C
    A &amp; B &amp; C --&gt;D(Fourth concept)</code></pre>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TB
    A(First concept) --&gt; B(Second concept)
    B --is part&lt;br&gt; of--&gt; A
    B--&gt;C(Third concept)
    A--&gt;C
    A &amp; B &amp; C --&gt;D(Fourth concept)
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<p>For the basics of using Mermaid with Quarto, see the <a href="https://quarto.org/docs/authoring/diagrams.html">Quarto docs</a>. A benefit of this approach is that you don’t have to worry too much about positioning, and you can publish your mind map easily on your blog! On the other hand, this approach doesn’t give you much flexibility and makes it harder to be creative about incorporating complex relationships. <strong>Doing your mind map by hand or in any other software is entirely fine</strong>.</p>
</section>
</section>
<section id="sec-classification-rates" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="sec-classification-rates">Classification Rates</h2>
<section id="part-1-1" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="part-1-1">Part 1</h4>
<div class="page-columns page-full"><p>COVID-19 rapid tests have approximately an 80% sensitivity rate, which means that, in an individual who truly has COVID-19, the probability of a rapid test giving a positive result is roughly 80%.  On the other hand, the probability of a rapid test giving a positive result for an individual who truly does <strong>not</strong> have COVID-19 is 5%. Suppose that approximately 4% of the population are currently infected with COVID-19. </p><div class="no-row-height column-margin column-container"><span class="margin-aside">These numbers are mostly made-up.</span><span class="margin-aside">Example 2.3.1 of <a href="https://github.com/probml/pml-book/releases/latest/download/book1.pdf">Murphy</a>, page 46, has a good review of the relevant probability and the definition of each of the rates below.</span></div></div>
<p>Write a Python function called <code>rate_summary</code> that prints the following output, filling in the correct values for each of the specified rates:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="fl">0.8</span>           <span class="co"># test sensitivity</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> <span class="fl">0.02</span>          <span class="co"># probability of positive test if no COVID</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>prevalence <span class="op">=</span> <span class="fl">0.05</span> <span class="co"># fraction of population infected</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>rate_summary(s, f, current_infection)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>The true positive rate is ___.
The false positive rate is ___.
The true negative rate is ___. 
The false positive rate is ___. </code></pre>
</section>
<section id="part-2-1" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="part-2-1">Part 2</h4>
<ol type="1">
<li>Suppose that scientists found an alternative rapid test which had a 75% sensitivity rate with a 0% chance of a positive test on someone who is truly not infected. Would you suggest replacing the old rapid tests with these alternative tests? Why? </li>
<li>What if the alternative test had an 85% sensitivity rate and a 10% chance of a positive test on someone who is truly not infected?</li>
</ol>
<div class="no-row-height column-margin column-container"><span class="margin-aside">You don’t necessarily need to use your function from the previous part in this part.</span></div></section>
<section id="part-3-1" class="level4">
<h4 class="anchored" data-anchor-id="part-3-1">Part 3</h4>
<p>It’s all well and good to do the math, but what about when we actually have data? Write a function called <code>rate_summary_2</code> that accepts two columns of a <code>pandas.DataFrame</code> (or equivalently two one-dimensional <code>numpy.arrays</code> of equal length). Call these <code>y</code> and <code>y_pred</code>. Assume that both <code>y</code> and <code>y_pred</code> are binary arrays (i.e.&nbsp;arrays of 0s and 1s). <code>y</code> represents the true outcome, whereas <code>y_pred</code> represents the prediction from an algorithm or test. Here’s an example of the kind of data we are thinking about:</p>
<div id="cell-29" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">"https://github.com/middlebury-csci-0451/CSCI-0451/raw/main/data/toy-classification-data.csv"</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(url)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>df.head() <span class="co"># just for visualizing the first few rows</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<div>
<div>


<table class="dataframe table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">y</th>
<th data-quarto-table-cell-role="th">y_pred</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</div>
<p>You should be able to use your function like this:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># y is the true label, y_pred is the prediction</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>rate_summary_2(df[<span class="st">"y"</span>], df[<span class="st">"y_pred"</span>]) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>The true positive rate is ___.
The false positive rate is ___.
The true negative rate is ___. 
The false positive rate is ___. </code></pre>
<section id="hints" class="level5">
<h5 class="anchored" data-anchor-id="hints">Hints</h5>
<p>An excellent solution for this part will not use any for-loops. Computing each of the four rates can be performed in a single compact line of code. To begin thinking of how you might do this, you may want to experiment with code like the following:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>df[[<span class="st">"y"</span>]] <span class="op">==</span> df[[<span class="st">"y_pred"</span>]]</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>df[[<span class="st">"y"</span>]].<span class="bu">sum</span>(), df[[<span class="st">"y"</span>]].<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>



</section>
</section>
</section>

<p><br> <br> <span style="color:grey;">© Phil Chodrow, 2024</span></p><div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-barabasStudyingReorientingStudy2020" class="csl-entry" role="listitem">
Barabas, Chelsea, Colin Doyle, Jb Rubinovitz, and Karthik Dinakar. 2020. <span>“Studying up: Reorienting the Study of Algorithmic Fairness Around Issues of Power.”</span> In <em>Proceedings of the 2020 <span>Conference</span> on <span>Fairness</span>, <span>Accountability</span>, and <span>Transparency</span></em>, 167–76. Barcelona Spain: ACM. <a href="https://doi.org/10.1145/3351095.3372859">https://doi.org/10.1145/3351095.3372859</a>.
</div>
<div id="ref-barocasFairnessMachineLearning2023" class="csl-entry" role="listitem">
Barocas, Solon, Moritz Hardt, and Arvind Narayanan. 2023. <em>Fairness and Machine Learning: Limitations and Opportunities</em>. Cambridge, Massachusetts: The MIT Press.
</div>
<div id="ref-dignazioDataFeminism2023" class="csl-entry" role="listitem">
D’Ignazio, Catherine, and Lauren F. Klein. 2023. <em>Data Feminism</em>. First MIT Press paperback edition. Cambridge, Massachusetts: The Mit Press.
</div>
<div id="ref-gebruDatasheetsDatasets2021" class="csl-entry" role="listitem">
Gebru, Timnit, Jamie Morgenstern, Briana Vecchione, Jennifer Wortman Vaughan, Hanna Wallach, Hal Daumé Iii, and Kate Crawford. 2021. <span>“Datasheets for Datasets.”</span> <em>Communications of the ACM</em> 64 (12): 86–92. <a href="https://doi.org/10.1145/3458723">https://doi.org/10.1145/3458723</a>.
</div>
<div id="ref-gormanEcologicalSexualDimorphism2014" class="csl-entry" role="listitem">
Gorman, Kristen B., Tony D. Williams, and William R. Fraser. 2014. <span>“Ecological <span>Sexual Dimorphism</span> and <span>Environmental Variability</span> Within a <span>Community</span> of <span>Antarctic Penguins</span> (<span>Genus Pygoscelis</span>).”</span> Edited by André Chiaradia. <em>PLoS ONE</em> 9 (3): e90081. <a href="https://doi.org/10.1371/journal.pone.0090081">https://doi.org/10.1371/journal.pone.0090081</a>.
</div>
<div id="ref-horstAllisonhorstPalmerpenguinsV02020" class="csl-entry" role="listitem">
Horst, Allison M, Alison Presmanes Hill, and Kristen B Gorman. 2020. <span>“Allisonhorst/Palmerpenguins: V0.1.0.”</span> Zenodo. <a href="https://doi.org/10.5281/ZENODO.3960218">https://doi.org/10.5281/ZENODO.3960218</a>.
</div>
<div id="ref-narayanan2022limits" class="csl-entry" role="listitem">
Narayanan, Arvind. 2022. <span>“The Limits of the Quantitative Approach to Discrimination.”</span> Speech.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>