{
  "hash": "943d3e09837b0a01e443d00fa4ec7b93",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Implementing Logistic Regression\"\ntype: \"Blog Post\"\ndate: 2024-04-04\ndescription: |\n    In this blog post, you'll implement several <i>first-order methods</i>: optimization algorithms based on the gradients of functions. You'll implement simple gradient descent, a momentum method, and stochastic gradient descent, comparing their performance for training logistic regression. \nobjectives: \n  - Theory\n  - Implementation\n  - Experimentation\npublish: \"false\"\n---\n\n::: {.hidden}\n$$\n\\newcommand{\\R}{\\mathbb{R}}\n\\newcommand{\\vx}{\\mathbf{x}}\n\\newcommand{\\vy}{\\mathbf{y}}\n\\newcommand{\\mX}{\\mathbf{X}}\n\\newcommand{\\vw}{\\mathbf{w}}\n\\newcommand{\\bracket}[1]{\\langle #1 \\rangle}\n\\newcommand{\\abs}[1]{\\lvert #1 \\rvert}\n\\newcommand{\\paren}[1]{\\left( #1 \\right)}\n$$\n\n:::\n\n## Introduction\n\n[Recently](https://www.philchodrow.prof/ml-notes/chapters/23-gradient-descent.html), we introduced the gradient descent algorithm for solving the empirical risk minimization problem. We also calculated the gradient of the loss function for logistic regression.  \n\nIn this blog post you will: \n\n1. Implement gradient descent for logistic regression in an object-oriented paradigm. \n2. Implement a key variant of gradient descent with *momentum* in order to achieve faster convergence. \n3. (Optionally), implement *Newton's Method* for even faster logistic regression. \n4. Perform experiments to test your implementations. \n\n\n## Part A: Implement Logistic Regression\n\n### Getting Started\n\n1. Please create a new blog post. In addition to the usual `.ipynb` file, please also create a script called `logistic.py` *in the same directory*. This is the file in which you will implement logistic regression. \n2. Then, in your `.ipynb` notebook file, place the following in a Python code block underneath your metadata block: \n\n```python\n%load_ext autoreload\n%autoreload 2\nfrom logistic import LogisticRegression, GradientDescentOptimizer\n```\n\nIf you complete the optional implementation of Newton's Method, you'll also need to import `NewtonOptimizer`. \n\n### Implement `LinearModel` and `LogisticRegression()`\n\nIf you haven't already, implement the methods of the `LinearModel` class as described in [this warmup](../../warmup-exercises.ipynb#sec-perceptron). Then, define a new class called `LogisticRegression` which inherits from `LinearModel`. This class should have two methods: \n\n- `LogisticRegression.loss(X, y)` should compute the empirical risk $L(\\mathbf{w})$ using the logistic loss function [As usual, $s_i = \\langle \\mathbf{w}, \\mathbf{x}_i \\rangle$ and $\\sigma(s) = \\frac{1}{1 + e^{-s}}$.]{.aside}\n$$\n\\begin{aligned}\n    L(\\mathbf{w}) = \\frac{1}{n} \\sum_{i = 1}^n \\left[-y_i \\log \\sigma(s_i) - (1-y_i)\\log (1-\\sigma(s_i))\\right]\n\\end{aligned}\n$$\nThe weight vector $\\mathbf{w}$ used for this calculation should be stored as an instance variable of the class. \n- `LogisticRegression.grad(X, y)` should compute the *gradient* of the empirical risk $L(\\mathbf{w})$. You can use [the formula](https://www.philchodrow.prof/ml-notes/chapters/23-gradient-descent.html#eq-logistic-gradient) for the gradient supplied in the lecture notes on gradient descent. \n\n### Implement `GradientDescentOptimizer.step()`\n\nNext, implement a `GradientDescentOptimizer` class. For this project, we are going to implement *gradient descent with momentum*, also known as Spicy Gradient Descent. Let $\\mathbf{w}_k$ be the estimate of the weight vector at algorithmic step $k$. Gradient descent with momentum performs the update [This description of gradient descent with momentum is based on @hardtPatternsPredictionsActions2022.]{.aside}\n$$\n\\begin{aligned}\n    \\mathbf{w}_{k+1} \\gets \\mathbf{w}_k - \\alpha \\nabla L(\\mathbf{w}_k) + \\beta(\\mathbf{w}_k - \\mathbf{w}_{k-1}) \n\\end{aligned}\n$${#eq-gradient-momentum}\n\nHere, $\\alpha$ and $\\beta$ are *two* learning rate parameters. When $\\beta = 0$ we have \"regular\" gradient descent. In practice, a choice of $\\beta \\approx 0.9$ or so is common. Implementing the momentum term isn't too complex -- you'll just need to create a new instance variable to hold the *previous* value of $\\mathbf{w}$ as well as the current one. \n\n## Part B: Experiments\n\n### Experimental Data\n\nHere is some code to generate data for a classification problem. You can control the number of points by adjusting `n_points`, the number of features by adjusting `p_dims`, and the difficulty of the classification problem by adjusting the `noise` (higher noise is a harder problem). \n\n```python\ndef classification_data(n_points = 300, noise = 0.2, p_dims = 2):\n    \n    y = torch.arange(n_points) >= int(n_points/2)\n    y = 1.0*y\n    X = y[:, None] + torch.normal(0.0, noise, size = (n_points,p_dims))\n    X = torch.cat((X, torch.ones((X.shape[0], 1))), 1)\n    \n    return X, y\n\nX, y = classification_data(noise = 0.5)\n```\n\n### How to Train Your Model\n\nOnce you've correctly implemented logistic regression and gradient descent, you can do a gradient descent loop like this: \n\n```python\nLR = LogisticRegression() \nopt = GradientDescentOptimizer(LR)\n\nfor _ in range(100):\n    # add other stuff to e.g. keep track of the loss over time. \n    opt.step(X, y, alpha = 0.1, beta = 0.9)\n```\n\n### Experiments\n\nPlease perform experiments, with careful written explanations, that demonstrate the following statements: \n\n1. **Vanilla gradient descent**: When $p_dim = 2$, when $\\alpha$ is sufficiently small and $\\beta = 0$, gradient descent for logistic regression converges to a weight vector $\\mathbf{w}$ that looks visually correct (plot the decision boundary with the data). Furthermore, the loss decreases monotonically (plot the loss over iterations). \n    - This is a good experiment to use to assess whether your implementation in Part A has bugs. \n2. **Benefits of momentum**: On the same data, gradient descent with momentum (e.g. $\\beta = 0.9$) *can* converge to the correct weight vector in fewer iterations than vanilla gradient descent (with $\\beta = 0$). Plot the loss over iterations for each method. You may need to experiment with the data and choice of $\\alpha$ in order to observe speedups due to momentum. \n3. **Overfitting**: Generate some data where `p_dim > n_points`. For example, `p_dim = 100` and `n_points = 50`. Do this **twice** with the exact same parameters. Call the first dataset  `X_train, y_train` and the second dataset `X_test, y_test`. Then, do an experiment in which you fit a logistic regression model to the data `X_train, y_train` and obtain 100% accuracy on this training data. What is the accuracy on the test data?  \n\n\n\n\n\n## 1. Implement Logistic Regression \n\nIn your source file, implement a `LogisticRegression()` class. Your class should have similar user-facing functions as the `Perceptron()` class from the [previous blog post](blog-post-perceptron.qmd). These are: \n\n- `LogisticRegression.fit(X, y)` is the primary method. This method has no return value. If `LR` is a `LogisticRegression` object, then after `LR.fit(X, y)` is called, `LR` should have an instance variable of *weights* called `w`. This `w` is the vector of weights, including the bias term $b$. `LR` should have an instance variable called `LR.loss_history` which is a list of the evolution of the `loss` over the training period (see `LogisticRegression.loss(X, y)` below). Finally, `LR` should have an instance variable called `LR.score_history` which is a list of the evolution of the `score` over the training period (see `LogisticRegression.score(X, y)` below).\n- `LogisticRegression.predict(X)` should return a vector $\\hat{\\vy} \\in \\{0,1\\}^n$ of predicted labels. These are the model's predictions for the labels on the data. \n- `LogisticRegression.score(X, y)` should return the *accuracy* of the predictions as a number between 0 and 1, with 1 corresponding to perfect classification. \n- `LogisticRegression.loss(X, y)` should return the overall loss (empirical risk) of the current weights on `X` and `y`. \n\n### Gradient Descent\n\nYour `LogisticRegression.fit` method should use gradient descent as described in lecture. Allow the user to specify the learning rate $\\alpha$ and the maximum number of iterations, which for this blog post we'll call *epochs*. So, using the  `fit` method might look like this: \n\n::: {#c64ad2ad .cell execution_count=2}\n``` {.python .cell-code}\nfrom solutions.logistic import LogisticRegression # your source code\nfrom sklearn.datasets import make_blobs\nfrom matplotlib import pyplot as plt\nimport numpy as np\nnp.seterr(all='ignore') \n\n# make the data\np_features = 3\nX, y = make_blobs(n_samples = 200, n_features = p_features - 1, centers = [(-1, -1), (1, 1)])\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n```\n\n::: {.cell-output .cell-output-display}\n![](blog-post-optimization_files/figure-html/cell-2-output-1.png){width=587 height=429}\n:::\n:::\n\n\n::: {#7f87a7b7 .cell execution_count=3}\n``` {.python .cell-code}\n# fit the model\n\nLR = LogisticRegression()\nLR.fit(X, y, alpha = 0.1, max_epochs = 1000)\n\n# inspect the fitted value of w\nLR.w \n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n```\n\n::: {.cell-output .cell-output-display}\n![](blog-post-optimization_files/figure-html/cell-3-output-1.png){width=587 height=429}\n:::\n:::\n\n\n### Stochastic Gradient Descent\n\nNow implement an alternative version of the `fit` method called `fit_stochastic`. In this method, you will implement *stochastic gradient descent*. In stochastic gradient descent, we don't compute the complete gradient \n\n$$\n\\nabla L(\\vw) = \\frac{1}{n}\\sum_{i = 1}^n \\nabla \\ell(f_{\\vw}(\\vx_i), y_i)\\;. \n$$\n\nInstead, we compute a *stochastic gradient* by picking a random subset $S \\subseteq [n] = \\{1, \\ldots, n\\}$ and computing \n\n$$\n\\nabla_S L(\\vw) = \\frac{1}{\\abs{S}}\\sum_{i \\in S} \\nabla \\ell(f_{\\vw}(\\vx_i), y_i)\\;. \n$$\n\nThe size of $S$ is called the *batch size*. Typically, we cycle through all the points $1$ through $n$ in the following way: \n\n1. Shuffle the points randomly. \n2. Pick the first $k$ random points, compute the stochastic gradient, and then perform an update. \n3. Pick the next $k$ random points and repeat..\n4. When we have gone through all $n$ points, reshuffle them all randomly and proceed again. \n\nThis process can be accomplished efficiently using the `np.array_split()` function, which will create batches for you. Here is some code to get you started; it will split the data into batches of size `batch_size`\n\n```python\n\nn = X.shape[0]\nfor j in np.arange(m_epochs):\n            \n    order = np.arange(n)\n    np.random.shuffle(order)\n\n    for batch in np.array_split(order, n // batch_size + 1):\n        x_batch = X[batch,:]\n        y_batch = y[batch]\n        grad = gradient(w, x_batch, y_batch) \n        # perform the gradient step\n        # ...\n```\n\nFor stochastic gradient descent, only update `self.loss_history` *at the end of each epoch*. This allows us to compare to regular gradient descent, since in both algorithms at the end of an epoch we have used every single point once. \n\n### Momentum (Optional)\n\nThe momentum method is described on p. 85 of [Hardt and Recht](https://via.hypothes.is/https://arxiv.org/pdf/2102.05242.pdf). Implement the momentum method for stochastic gradient descent. My advice is to do so as an optional parameter for `fit_stochastic`. In my implementation, if the user sets `momentum = True` then I set the parameter $\\beta$ from Hardt and Recht to value `0.8`. Otherwise it is set to 0, and we have regular gradient descent. \n \n### Illustration\n\nHere is an example plot showing the evolution of the loss function for the three algorithms: \n\n::: {#86d63698 .cell .caption-undefined execution_count=4}\n``` {.python .cell-code}\nLR = LogisticRegression()\nLR.fit_stochastic(X, y, \n                  m_epochs = 100, \n                  momentum = True, \n                  batch_size = 10, \n                  alpha = .05) \n\nnum_steps = len(LR.loss_history)\nplt.plot(np.arange(num_steps) + 1, LR.loss_history, label = \"stochastic gradient (momentum)\")\n\nLR = LogisticRegression()\nLR.fit_stochastic(X, y, \n                  m_epochs = 100, \n                  momentum = False, \n                  batch_size = 10, \n                  alpha = .1)\n\nnum_steps = len(LR.loss_history)\nplt.plot(np.arange(num_steps) + 1, LR.loss_history, label = \"stochastic gradient\")\n\nLR = LogisticRegression()\nLR.fit(X, y, alpha = .05, max_epochs = 100)\n\nnum_steps = len(LR.loss_history)\nplt.plot(np.arange(num_steps) + 1, LR.loss_history, label = \"gradient\")\n\nplt.loglog()\n\nlegend = plt.legend() \n```\n\n::: {.cell-output .cell-output-display}\n![Evolution of the training loss for three optimization algorithms.](blog-post-optimization_files/figure-html/cell-4-output-1.png){width=603 height=415}\n:::\n:::\n\n\nFor these settings, stochastic gradient descent with and without momentum tends to get to a \"pretty good\" result faster than standard gradient descent, but these random algorithms can \"bounce around\" near the good solution. Standard gradient descent might need more epochs to find a good solution, but quickly \"settles down\" once it finds it. \n\n\n## 2. Perform Experiments\n\nAfter you have tested and implemented your class, please perform experiments in which you show examples of the following phenomena: \n\n1. A case in which gradient descent does not converge to a minimizer because the learning rate $\\alpha$ is too large. \n2. A case in which the choice of batch size influences how quickly the algorithm converges. \n3. If you implemented momentum, a case in which the use of momentum significantly speeds up convergence. \n\nIn at least one of these experiments, generate some synthetic data (it's fine to use `make_blobs`) for data of at least 10 feature dimensions. \n\n## 3. Document and Write\n\nPlease include informative comments throughout your source code, **and a thorough docstring** for each of your `fit` and `fit_stochastic` methods. \n\nIn your blog post, please describe both your approach to implementing your algorithm and the findings of your experiments. \n\n## 4. Submit\n\nSubmit your blog post, making sure to include a link to the online version of your source code at the top of your post. \n\n\n\n## Tips and Hints  \n\nMost of the major math functions are shown in our [lecture on gradient descent](../../lecture-notes/gradient-descent.qmd). You're welcome to use any of these functions as you wish; please just incorporate comments in your code and blog post to cite where they came from.  \n\nIf you compute the gradient using matrix-vector operations in `numpy` (recommended, no for-loops!), you may find it useful at some point to convert an `np.array()` of shape `(n,)` to an `np.array()` of shape `(n,1)` like this: \n\n::: {#55cad86f .cell execution_count=5}\n``` {.python .cell-code}\nv = np.random.rand(5)\nv\n```\n\n::: {.cell-output .cell-output-display execution_count=4}\n```\narray([0.68796799, 0.22833394, 0.04932159, 0.10185557, 0.1775419 ])\n```\n:::\n:::\n\n\n::: {#ce047fee .cell execution_count=6}\n``` {.python .cell-code}\nv[:,np.newaxis]\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\narray([[0.68796799],\n       [0.22833394],\n       [0.04932159],\n       [0.10185557],\n       [0.1775419 ]])\n```\n:::\n:::\n\n\nYou will find it convenient again to ensure that `X` contains a column of `1`s prior to any major computations. I defined this function: \n\n```python\ndef pad(X):\n    return np.append(X, np.ones((X.shape[0], 1)), 1)\n```\n\nand called it at a few strategic places in my implementation. \n \nMy complete implementation, including all the math functions, momentum, etc. but excluding comments, was about 100 lines of code. \n\nYou're welcome to find creative ways to visualize your findings. You might also find it interesting to visualize the score (not just the loss). However, this is optional. \n\n",
    "supporting": [
      "blog-post-optimization_files"
    ],
    "filters": [],
    "includes": {}
  }
}